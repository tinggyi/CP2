import os
import re
import fitz  # PyMuPDF library
from google.cloud import vision

# --- 1. SETUP AND AUTHENTICATION ---
# This remains the same, setting up your Google Cloud credentials.
credential_path = r"D:\CP2_Project\cp2-asag-4705d96681dc.json"
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path
client = vision.ImageAnnotatorClient()


# --- 2. CORE FUNCTIONS ---
def ocr_pdf_to_text(pdf_path):
    """
    Performs OCR on each PDF page and merges consecutive pages intelligently
    so questions spanning pages are kept together.
    """
    print(f" Processing PDF: {pdf_path}...")
    if not os.path.exists(pdf_path):
        print(f"Error: File not found at '{pdf_path}'")
        return ""

    doc = fitz.open(pdf_path)
    full_text_from_pdf = ""
    text_detected = False
    prev_page_text = ""

    for page_num, page in enumerate(doc):
        print(f"  - Reading page {page_num + 1}...")
        pix = page.get_pixmap(dpi=300)
        img_bytes = pix.tobytes("png")

        image = vision.Image(content=img_bytes)
        response = client.document_text_detection(image=image)

        if not response.full_text_annotation:
            continue

        page_text = response.full_text_annotation.text.strip()

        # Skip any front matter until we see Question 1
        if not text_detected:
            if "Question" in page_text:
                text_detected = True
            else:
                continue

        # Merge consecutive pages smoothly
        # If the previous page doesn't end with a full stop or "marks)", assume it's cut
        if prev_page_text and not re.search(r'[\.\)\?]$', prev_page_text.strip()):
            full_text_from_pdf = full_text_from_pdf.rstrip() + " " + page_text + "\n\n"
        else:
            full_text_from_pdf += page_text + "\n\n"

        prev_page_text = page_text

    doc.close()
    print("‚úÖ OCR processing complete.")

    # --- Clean up common page footer artifacts ---
    footer_patterns = [
        r'Page\s*\d+\s*of\s*\d+',  # e.g., "Page 2 of 3"
        r'Faculty of Engineering and Technology',
        r'CSC\d{4}/[A-Za-z]+\s*\d{4}\s*Final Examination',
        r'-{3,}',  # horizontal lines like "-----"
    ]

    for pattern in footer_patterns:
        full_text_from_pdf = re.sub(pattern, '', full_text_from_pdf, flags=re.IGNORECASE)

    # Clean up extra blank lines after removal
    full_text_from_pdf = re.sub(r'\n{2,}', '\n\n', full_text_from_pdf)

    return full_text_from_pdf



def extract_questions_and_answers(text):
    import re
    qa_data = {}

    print("\n[DEBUG] Raw text length:", len(text))

    # ‚úÖ FIXED: Only split when "Question X" appears at start of a new line (not mid-sentence)
    main_blocks = re.split(
        r'(?:(?:^|\n|\r)\s*)(?=Question\s*\d+\b)',
        text,
        flags=re.IGNORECASE
    )
    print(f"[DEBUG] Total split blocks: {len(main_blocks)}")

    cleaned_blocks = []
    seen_questions = set()

    # --- Clean and collect unique question blocks ---
    for block in main_blocks:
        block = block.strip()
        if not block:
            continue
        match = re.match(r'Question\s*(\d+)', block, flags=re.IGNORECASE)
        if not match:
            continue
        qnum = match.group(1)
        if qnum in seen_questions:
            print(f"‚ö†Ô∏è Skipping duplicate Question {qnum}")
            continue
        seen_questions.add(qnum)
        cleaned_blocks.append((f"Question {qnum}", block))

    print(f"[DEBUG] Unique questions detected: {seen_questions}")

    # --- Process each question block ---
    for header, main_q_text in cleaned_blocks:
        main_q_num = re.search(r'\d+', header).group()
        print(f"\n[DEBUG] üß© Processing {header}")

        # Find start of a)
        sub_start = re.search(r'(?m)^(?:\s*)[aA]\s*\)', main_q_text)
        if sub_start:
            # Cut off preamble (like "Question 2 (Total: 13 marks)")
            main_q_text = main_q_text[sub_start.start():]
        else:
            print(f"‚ö†Ô∏è No 'a)' found for {header}, checking fallback.")
            # Handle non-sub-question case
            parts = re.split(r'\(\s*\d+\s*mark[s]?\s*\)', main_q_text, maxsplit=1, flags=re.IGNORECASE)
            if len(parts) >= 2:
                question_text = re.sub(r'Question\s*\d+\s*', '', parts[0], 1, flags=re.IGNORECASE).strip().replace('\n', ' ')
                answer_text = parts[1].strip()
                # ‚úÖ Extract marks (skip total)
                marks_match = re.search(r'\((\d+)\s*marks?\)', main_q_text, re.IGNORECASE)
                marks = int(marks_match.group(1)) if marks_match and not re.search(r'Total', main_q_text, re.IGNORECASE) else None
                qa_data[f"{main_q_num}"] = {"question": question_text, "answer": answer_text, "marks": marks}
                print(f"‚úÖ Captured full Question {main_q_num} (no sub-questions)")
            else:
                print(f"‚ùå Failed to parse {header} (no 'a)' or marks found).")
            continue

        # --- Split into subquestions (a), b), etc.) ---
        sub_blocks = re.split(
            r'(?:(?<=^)|(?<=\n)|(?<=\r))\s*([a-z]\))(?=\s*\S)',
            main_q_text,
            flags=re.IGNORECASE | re.MULTILINE
        )
        rebuilt_blocks = []
        for j in range(1, len(sub_blocks), 2):
            label = sub_blocks[j].strip()
            content = sub_blocks[j + 1].strip() if j + 1 < len(sub_blocks) else ""
            rebuilt_blocks.append(label + " " + content)

        # --- Process each sub-question ---
        for sub_block in rebuilt_blocks:
            sub_block = sub_block.strip()
            if not sub_block:
                continue

            parent_match = re.match(r'^([a-z])\)', sub_block, flags=re.IGNORECASE)
            if not parent_match:
                continue
            parent_id = parent_match.group(1).lower()

            # ‚úÖ Split nested parts (i), ii), or nested a), b), etc.)
            nested_splitter = r'(?=\s*\bi{1,3}\.)'
            nested_parts = re.split(nested_splitter, sub_block, flags=re.IGNORECASE)

            # --- CASE 1: Simple part (no nested subparts) ---
            if len(nested_parts) <= 1:
                # ‚úÖ Capture marks but ignore (Total: X marks)
                marks_match = re.search(r'\((\d+)\s*marks?\)', sub_block, re.IGNORECASE)
                marks = int(marks_match.group(1)) if marks_match and not re.search(r'Total', sub_block, re.IGNORECASE) else None

                parts = re.split(r'\(\s*\d+\s*mark[s]?\s*\)', sub_block, maxsplit=1, flags=re.IGNORECASE)
                if len(parts) < 2:
                    print(f"‚ö†Ô∏è No '(x marks)' found in {main_q_num}{parent_id}")
                    continue
                question_text = parts[0].strip().replace('\n', ' ')
                answer_text = parts[1].strip()
                qa_data[f"{main_q_num}{parent_id}"] = {
                    "question": question_text,
                    "answer": answer_text,
                    "marks": marks
                }
                print(f"‚úÖ Captured: Question {main_q_num}{parent_id} ({marks} marks)")

            # --- CASE 2: Nested part (like Q1b_i, Q2b_a, etc.) ---
            else:
                print(f"‚ÑπÔ∏è Found nested parts in Question {main_q_num}{parent_id}")

                for i, part in enumerate(nested_parts):
                    part = part.strip()
                    if not part:
                        continue

                    # ‚úÖ Capture marks but skip (Total)
                    marks_match = re.search(r'\((\d+)\s*marks?\)', part, re.IGNORECASE)
                    marks = int(marks_match.group(1)) if marks_match and not re.search(r'Total', part, re.IGNORECASE) else None

                    parts = re.split(r'\(\s*\d+\s*mark[s]?\s*\)', part, maxsplit=1, flags=re.IGNORECASE)
                    if len(parts) < 2:
                        print(f"‚ÑπÔ∏è Skipping non-answer container: {part[:40]}")
                        continue

                    question_text = parts[0].strip().replace('\n', ' ')
                    answer_text = parts[1].strip()

                    # Identify nested label (roman or letter)
                    roman_match = re.match(r'^(i{1,3})\.', part, flags=re.IGNORECASE)
                    letter_match = re.match(r'^([a-z])\)', part, flags=re.IGNORECASE)

                    if roman_match:
                        key = f"{main_q_num}{parent_id}_{roman_match.group(1)}"
                    elif letter_match:
                        key = f"{main_q_num}{parent_id}_{letter_match.group(1)}"
                    else:
                        key = f"{main_q_num}{parent_id}_{i}"

                    qa_data[key] = {
                        "question": question_text,
                        "answer": answer_text,
                        "marks": marks
                    }
                    print(f"‚úÖ Captured: Question {key} ({marks} marks)")

    return qa_data



# --- 3. MAIN WORKFLOW ---

answer_key_pdf_path = "exam_latest.pdf" # Make sure this is a PDF
student_answer_pdf_path = "exam_latest.pdf"

answer_key_text = ocr_pdf_to_text(answer_key_pdf_path)
student_answer_text = ocr_pdf_to_text(student_answer_pdf_path)

# c. Parse the text to separate questions and answers.
structured_qa_data = extract_questions_and_answers(answer_key_text)
student_qa_data = extract_questions_and_answers(student_answer_text)
print("\n" + "="*20 + " COMBINED QUESTION REPORT " + "="*20)

# Get all question keys from reference and student data
all_keys = sorted(set(structured_qa_data.keys()) | set(student_qa_data.keys()))

for key in all_keys:
    ref_data = structured_qa_data.get(key)
    stu_data = student_qa_data.get(key)

    print(f"\n{'='*90}")
    print(f"Question {key}")

    # --- Question text ---
    if ref_data and "question" in ref_data:
        print(f"\nQuestion Text:\n{ref_data['question']}")
    elif stu_data:
        print(f"\nQuestion Text:\n{stu_data['question']}")
    else:
        print("\nQuestion Text: [Not found]")

      # --- Marks ---
    marks_display = ref_data["marks"] if ref_data and ref_data.get("marks") else "N/A"
    print(f"Marks: {marks_display}")

    # --- Reference Answer ---
    print("\nReference Answer:")
    if ref_data and ref_data.get("answer"):
        print(ref_data["answer"])
    else:
        print("[No reference answer found]")

    # --- Student Answer ---
    print("\nStudent Answer:")
    if stu_data and stu_data.get("answer"):
        print(stu_data["answer"])
    else:
        print("[No student answer found]")

# import pytesseract
# import cv2
# from PIL import Image
# import matplotlib.pyplot as plt
# import numpy as np

# # Path to tesseract
# pytesseract.pytesseract.tesseract_cmd = r"D:\TesseractOCR\tesseract.exe"
# img = cv2.imread("sample_image7.jpeg", 0)

# scaled = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
# # denoised_img = cv2.GaussianBlur(scaled, (9, 9), 0)


# # bi_img = cv2.adaptiveThreshold(
# #     denoised_img,
# #     255,
# #     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
# #     cv2.THRESH_BINARY,
# #     3,
# #     1
# # )

# # 3. OCR and Output
# pil_img = Image.fromarray(scaled)
# final_text = pytesseract.image_to_string(scaled, lang="eng")

# # Display the final processed image
# plt.figure()
# plt.title("‚úÖ Final Adaptive Thresholding Result")
# plt.imshow(scaled, cmap='gray')
# plt.axis('off')
# plt.show()

# print(f"üìù OCR output:\n{final_text}")

# # Save the final best image
# pil_img.save("processed_300dpi_adaptive.png", dpi=(300, 300))


# text = pytesseract.image_to_string(pil_img, lang="eng")

# print("Captured text:")
# print(text)

# hist = cv2.calcHist([gray_img], [0], None, [256], [0,256])
# plt.figure()
# plt.plot(hist)
# plt.title("Processed image")

# kernel = np.array([[0, -1, 0],
#                    [-1, 5, -1],
#                    [0, -1, 0]])

# sharpened = cv2.filter2D(noise_filtered_img, -1, kernel)

# kernel_morph = np.ones((1, 1), np.uint8)
# sharpened = cv2.morphologyEx(sharpened, cv2.MORPH_CLOSE, kernel_morph)

